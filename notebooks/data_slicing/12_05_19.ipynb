{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12/5/19\n",
    "\n",
    "Seeing if we've actually reproduced CheXNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import math\n",
    "import os\n",
    "import os.path as osp\n",
    "import json\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "os.chdir('/lfs/1/gangus/repositories/pytorch-classification/Emmental-ChexNet')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sklearn.metrics as skl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import emmental\n",
    "from emmental import Meta\n",
    "from emmental.data import EmmentalDataLoader\n",
    "from emmental.learner import EmmentalLearner\n",
    "from emmental.model import EmmentalModel\n",
    "from emmental.scorer import Scorer\n",
    "from emmental.task import EmmentalTask\n",
    "\n",
    "from dataset import CXR8Dataset\n",
    "from task import get_task\n",
    "from task_config import CXR8_TASK_NAMES\n",
    "from transforms import get_data_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emmental_dir = '/lfs/1/gangus/repositories/pytorch-classification/Emmental-ChexNet/logs/2019_12_04/14_31_34/99ae8f45'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ce_loss(task_name, immediate_ouput_dict, Y, active):\n",
    "    module_name = f\"{task_name}_pred_head\"\n",
    "    return F.cross_entropy(\n",
    "        immediate_ouput_dict[module_name][0][active], (Y.view(-1) - 1)[active]\n",
    "    )\n",
    "\n",
    "def output(task_name, immediate_ouput_dict):\n",
    "    module_name = f\"{task_name}_pred_head\"\n",
    "    return F.softmax(immediate_ouput_dict[module_name][0], dim=-1)\n",
    "\n",
    "DATA_NAME = 'CXR8'\n",
    "\n",
    "image_path = '/lfs/1/jdunnmon/data/nih/images/images'\n",
    "data_path = '/dfs/scratch1/senwu/mmtl/emmental-tutorials/chexnet/data/nih_labels.csv'\n",
    "\n",
    "task_names = CXR8_TASK_NAMES\n",
    "task_to_label_dict = {t: t for t in task_names}\n",
    "add_binary_triage_label = False\n",
    "batch_size = 16\n",
    "\n",
    "emmental.init()\n",
    "split = 'val'\n",
    "\n",
    "model_config = {\n",
    "    'model_path': osp.join(emmental_dir, 'best_model_model_all_val_loss.pth.pth'),\n",
    "    'device': 0,\n",
    "    'dataparallel': True\n",
    "}\n",
    "\n",
    "cxr8_transform = get_data_transforms(DATA_NAME)\n",
    "dataset = CXR8Dataset(\n",
    "    name=DATA_NAME,\n",
    "    path_to_images=image_path,\n",
    "    path_to_labels=data_path,\n",
    "    split=split,\n",
    "    transform=cxr8_transform[split],\n",
    "    sample=0,\n",
    "    seed=1701,\n",
    "    add_binary_triage_label=add_binary_triage_label,\n",
    ")\n",
    "\n",
    "dataloader = EmmentalDataLoader(\n",
    "    task_to_label_dict=task_to_label_dict,\n",
    "    dataset=dataset,\n",
    "    split=split,\n",
    "    shuffle=True if split == \"train\" else False,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=16,\n",
    ")\n",
    "\n",
    "tasks = get_task(task_names)\n",
    "model = EmmentalModel(name=DATA_NAME, tasks=tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Meta.config[\"model_config\"][\"model_path\"]:\n",
    "    model.load(Meta.config[\"model_config\"][\"model_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task_name in dataset.Y_dict.keys():\n",
    "    print(task_name)\n",
    "    print(sum(dataset.Y_dict[task_name] == 1).type(torch.DoubleTensor) / len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 5\n",
    "x, y = dataset[idx]\n",
    "image_index = x['image_name']\n",
    "print(data_df.loc[image_index])\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.) Determine Drain Prevalence in longitudinal exams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = '/lfs/1/jdunnmon/data/nih/images/images'\n",
    "preds_df = pd.read_csv('/lfs/1/gangus/repositories/pytorch-classification/drain_detector/data/chexnet/by-patient-id/split/all_v2.csv', index_col=0).set_index('Image Index')\n",
    "valid_df = pd.read_csv('/lfs/1/gangus/repositories/pytorch-classification/drain_detector/data/chexnet/by-patient-id/split/valid.csv', index_col=0).set_index('Image Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1484/1484 [00:01<00:00, 801.98it/s]\n",
      "100%|██████████| 30726/30726 [00:31<00:00, 965.75it/s] \n"
     ]
    }
   ],
   "source": [
    "pos_pneumo = preds_df.loc[(preds_df['Pneumothorax'] == 1)]\n",
    "neg_pneumo = preds_df.loc[(preds_df['Pneumothorax'] == 0)]\n",
    "\n",
    "subsets = [('pos_pneumo', pos_pneumo), ('neg_pneumo', neg_pneumo)]\n",
    "subset_info = defaultdict(list)\n",
    "for subset_name, subset in subsets:\n",
    "    patient_id_groups = subset.groupby('Patient ID')\n",
    "    for patient_id, patient_id_group in tqdm(patient_id_groups):\n",
    "        subset_info[subset_name].append({\n",
    "            'patient_id': patient_id,\n",
    "            'num_images': len(patient_id_group),\n",
    "            'num_drains': sum(patient_id_group['drain'] == 1),\n",
    "            'num_normal': sum(patient_id_group['drain'] == 0),\n",
    "            'pairable': sum(patient_id_group['drain'] == 1) > 1 and sum(patient_id_group['drain'] == 0) > 1\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'pos_pneumo': defaultdict(int,\n",
       "                         {'patients': 1484,\n",
       "                          'pairable': 208,\n",
       "                          'num_images': 2240,\n",
       "                          'num_drains': 1490,\n",
       "                          'num_normal': 750,\n",
       "                          'pairable_frac': 0.14016172506738545}),\n",
       "             'neg_pneumo': defaultdict(int,\n",
       "                         {'patients': 30726,\n",
       "                          'pairable': 3570,\n",
       "                          'num_images': 53326,\n",
       "                          'num_drains': 23042,\n",
       "                          'num_normal': 30284,\n",
       "                          'pairable_frac': 0.11618824448349932})})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = defaultdict(lambda: defaultdict(int))\n",
    "for subset, info in subset_info.items():\n",
    "    for row in info:\n",
    "        counts[subset]['patients'] += 1\n",
    "        if row['pairable']:\n",
    "            counts[subset]['pairable'] += 1\n",
    "            counts[subset]['num_images'] += row['num_images']\n",
    "            counts[subset]['num_drains'] += row['num_drains']\n",
    "            counts[subset]['num_normal'] += row['num_normal']\n",
    "for subset_name, _ in subsets:\n",
    "    counts[subset_name]['pairable_frac'] = counts[subset_name]['pairable'] / counts[subset_name]['patients']\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairable_patients = defaultdict(list)\n",
    "for subset, info in subset_info.items():\n",
    "    for row in info:\n",
    "        if row['pairable']:\n",
    "            pairable_patients[subset].append(row['patient_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "subset_name = 'neg_pneumo'\n",
    "idx = 6\n",
    "\n",
    "pairable_patient = pairable_patients[subset_name][idx]\n",
    "target_rows = preds_df.loc[(preds_df['Patient ID'] == pairable_patient)]\n",
    "target_rows = target_rows.loc[target_rows['Pneumothorax'] == (1 if subset_name == 'pos_pneumo' else 0)]\n",
    "print(len(target_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_rows = preds_df.loc[(preds_df['Patient ID'] == pairable_patient)]\n",
    "target_rows = target_rows.loc[target_rows['Pneumothorax'] == (1 if subset_name == 'pos_pneumo' else 0)]\n",
    "\n",
    "# y_true_rows = valid_df.loc[valid_df['Patient ID'] == target['patient_id']]\n",
    "plt.rcParams['figure.figsize'] = [30, 10 * math.ceil(len(target_rows)/3)]\n",
    "\n",
    "fig, axs = plt.subplots(math.ceil(len(target_rows)/3), 3)\n",
    "if isinstance(axs[0], np.ndarray):\n",
    "    axs = [ax for ax_row in axs for ax in ax_row]\n",
    "    \n",
    "\n",
    "print(np.array(target_rows['drain']))\n",
    "# print(list(y_true_rows['drain']))\n",
    "\n",
    "\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    if i > len(target_rows) - 1:\n",
    "        axs[i].set_axis_off()\n",
    "    else:\n",
    "        row = target_rows.iloc[i]\n",
    "        image_path = osp.join(image_dir, row.name)\n",
    "        img = Image.open(image_path)\n",
    "        axs[i].imshow(img, cmap=plt.cm.bone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
