{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11/13/19\n",
    "\n",
    "Got the LMCL model working to some degree on high-dimensional data. However, there was some issue that caused a NaN loss halfway through model training. I might just drop this endeavor and continue onto greener pastures i.e. data slicing or mutual information maximization.\n",
    "\n",
    "Update: LMCL loss doesn't mitigate subclass underperformance. Run the following cells to visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.chdir('/lfs/1/gangus/repositories/pytorch-classification')\n",
    "\n",
    "import os.path as osp\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "\n",
    "import models.cifar as models\n",
    "from analysis.analysis_utils import load_trained_model, fetch_dataloaders, get_coarse_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_paths = {\n",
    "    'baseline': 'experiments/CIFAR100/superclass/baseline/1',\n",
    "    'lmcl': 'experiments/CIFAR100/superclass/lmcl/11_14_19-completed'\n",
    "}\n",
    "\n",
    "experiment_configs = {}\n",
    "for exp_name, exp_path in experiment_paths.items():\n",
    "    with open(osp.join(exp_path, 'config.json')) as f:\n",
    "        experiment_configs[exp_name] = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 20 classes...\n",
      "Using coarse labels...\n",
      "Using coarse labels...\n"
     ]
    }
   ],
   "source": [
    "config = experiment_configs['lmcl']\n",
    "\n",
    "superclass = config['superclass']\n",
    "cifar_type = config['cifar_type']\n",
    "model_name = config['model_name']\n",
    "model_args = config['model_args']\n",
    "checkpoint_dir = config['checkpoint_dir']\n",
    "trained_model, trained_criterion = load_trained_model(cifar_type, model_name, model_args, checkpoint_dir, lmcl_args={'feat_dim': 342, **config['criterion_args']})\n",
    "\n",
    "data_dir = config['data_dir']\n",
    "dataset_configs = config['dataset_configs']\n",
    "dataloader_configs = config['dataloader_configs']\n",
    "dataloaders = fetch_dataloaders(data_dir, cifar_type, superclass, dataset_configs, dataloader_configs)\n",
    "\n",
    "# Getting class-to-index maps for CIFAR100\n",
    "class_to_idx = {}\n",
    "class_to_idx['super'] = dataloaders['test'].dataset.class_to_idx\n",
    "class_to_idx['sub'] = dataloaders['test'].dataset.fine_class_to_idx\n",
    "\n",
    "idx_to_class = {}\n",
    "for tp in ['super', 'sub']:\n",
    "    idx_to_class[tp] = {v:k for k, v in class_to_idx[tp].items()}\n",
    "    \n",
    "trained_model = trained_model.to('cpu')\n",
    "trained_model = trained_model.module.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [01:48<00:12,  1.20s/it]"
     ]
    }
   ],
   "source": [
    "filenames_all = []\n",
    "coarse_labels_all = []\n",
    "fine_labels_all = []\n",
    "fine_preds_all = []\n",
    "preds_all = []\n",
    "losses_all = []\n",
    "softmax_all = []\n",
    "features_all = []\n",
    "\n",
    "t = tqdm(total=len(dataloaders['test']))\n",
    "for batch_idx, (inputs, \n",
    "                targets, \n",
    "                coarse_labels, \n",
    "                fine_labels, \n",
    "                filenames) in enumerate(dataloaders['test']):\n",
    "    \n",
    "    inputs, targets = inputs.cpu(), targets.cpu()\n",
    "    inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "    \n",
    "    emb, _ = trained_model(inputs)\n",
    "    outputs, mlogits = trained_criterion(emb, targets)\n",
    "    _, preds = outputs.topk(1, 1, True, True)\n",
    "    soft = torch.nn.Softmax(dim=-1)(outputs)\n",
    "    # feats = extract_resnext_features(trained_model,inputs)\n",
    "    \n",
    "    coarse_labels_all+=list([int(a) for a in coarse_labels])\n",
    "    fine_labels_all+=list([int(a) for a in fine_labels])\n",
    "    preds_all+=list([int(a) for a in preds])\n",
    "    softmax_all+=list([a.detach().cpu().numpy() for a in soft])\n",
    "    # features_all+=list([a.detach().cpu().numpy() for a in feats])\n",
    "    filenames_all+=list(filenames)\n",
    "    t.update()\n",
    "t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_dict = {\n",
    "    'filename':filenames_all,\n",
    "    'fine_labels':fine_labels_all,\n",
    "    'coarse_labels':coarse_labels_all,\n",
    "    'preds':preds_all,\n",
    "    'fine_labels_string': [idx_to_class['sub'][a] for a in fine_labels_all],\n",
    "    'coarse_labels_string': [idx_to_class['super'][a] for a in coarse_labels_all],\n",
    "    # 'features':features_all,\n",
    "    'softmax':softmax_all,\n",
    "}\n",
    "with open(f\"{checkpoint_dir}/predictions.pkl\",'wb') as f:\n",
    "   pickle.dump(preds_dict, f)\n",
    "\n",
    "prediction_df = pd.DataFrame(preds_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_results = get_coarse_accuracies(prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melting dataframe for plotting\n",
    "plot_df = pd.DataFrame(coarse_results).reset_index()\n",
    "plot_df = plot_df.rename(columns={\"index\": \"Superclass\"})\n",
    "plot_df = plot_df.melt(id_vars=['Superclass'], var_name='Subset', value_name='Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.2) \n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_style({'font.family':'serif'})\n",
    "\n",
    "font = font_manager.FontProperties(family='Dejavu Serif',\n",
    "                                   style='normal', size=16)\n",
    "plt.rcParams.update({'font.family': 'serif'})\n",
    "\n",
    "palette = [sns.xkcd_rgb[\"black\"]] + 5*[sns.xkcd_rgb[\"blue\"]]\n",
    "sns.set(font_scale=1.5)\n",
    "f = plt.figure(figsize=(10,10))\n",
    "ax = sns.stripplot(x=\"Superclass\", y=\"Accuracy\", hue=\"Subset\", data=plot_df, jitter=False, s=20, palette=palette, alpha=0.5)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=90,fontdict={'family':'Dejavu Serif'})\n",
    "# ax.set_yticklabels(ax.get_yticklabels(),fontdict={'family':'Dejavu Serif'})\n",
    "ax.set_xlabel(ax.get_xlabel(),fontdict={'family':'Dejavu Serif'})\n",
    "ax.set_ylabel(ax.get_ylabel(),fontdict={'family':'Dejavu Serif'})\n",
    "h,l = ax.get_legend_handles_labels()\n",
    "l[1] = 'Subclasses'\n",
    "l[0] = 'Superclass'\n",
    "ax.legend_.remove()\n",
    "ax.legend(h[0:2],l[0:2], ncol=1, loc='lower right',prop=font)\n",
    "ax.set_ylim([-0.02,1.02])\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{checkpoint_dir}/Superclass-Subclass-CIFAR-100-Correct-Val-v3.png',format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
