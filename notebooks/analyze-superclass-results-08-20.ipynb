{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models.cifar as models\n",
    "checkpoint_paths = {}\n",
    "checkpoint_paths['super'] = '/home/jdunnmon/Research/repos/pytorch-classification/checkpoints/cifar100/resnext-8x64d-epochs300-superclass'\n",
    "checkpoint_paths['sub'] = '/home/jdunnmon/Research/repos/pytorch-classification/checkpoints/cifar100/resnext-8x64d-epochs300-pretrained'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jdunnmon/Research/repos/pytorch-classification/models/cifar/resnext.py:81: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(self.classifier.weight)\n",
      "/home/jdunnmon/Research/repos/pytorch-classification/models/cifar/resnext.py:86: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(self.state_dict()[key], mode='fan_out')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 20 classes...\n",
      "Files already downloaded and verified\n",
      "Using coarse labels...\n",
      "Using coarse labels...\n",
      "Using 100 classes...\n",
      "Files already downloaded and verified\n",
      "Using fine labels...\n",
      "Using fine labels...\n"
     ]
    }
   ],
   "source": [
    "from analysis.analysis_utils import load_trained_model, fetch_dataloaders\n",
    "trained_models = {}\n",
    "dataloaders = {}\n",
    "ind_to_class = {}\n",
    "class_to_ind = {}\n",
    "for tp in ['super','sub']:\n",
    "    trained_models[tp], args = load_trained_model(checkpoint_paths[tp])\n",
    "    dataloaders[tp] = fetch_dataloaders(args)\n",
    "    class_to_ind[tp] = dataloaders[tp]['test'].dataset.class_to_idx\n",
    "    ind_to_class[tp] = {v:k for k,v in dataloaders[tp]['test'].dataset.class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "use_cuda = True\n",
    "outputs = []\n",
    "testloader = dataloaders['sub']['test']\n",
    "model = trained_models['sub']\n",
    "model.eval()\n",
    "if use_cuda:\n",
    "    trained_models['super'].cuda()\n",
    "    trained_models['sub'].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jdunnmon/Research/repos/anaconda3/envs/pytorch-classification/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "filenames_all = []\n",
    "coarse_labels_all = []\n",
    "fine_labels_all = []\n",
    "fine_preds_all = []\n",
    "coarse_preds_all = []\n",
    "\n",
    "for batch_idx, (inputs, targets, coarse_labels, fine_labels, filenames) in enumerate(testloader):\n",
    "\n",
    "    if use_cuda:\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "    inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)\n",
    "\n",
    "    # compute output\n",
    "    preds = {}\n",
    "    for tp in ['super','sub']:\n",
    "        outputs = trained_models[tp](inputs)\n",
    "        _, preds[tp] = outputs.topk(1, 1, True, True)\n",
    "    \n",
    "    coarse_labels_all+=list([int(a) for a in coarse_labels])\n",
    "    fine_labels_all+=list([int(a) for a in fine_labels])\n",
    "    coarse_preds_all+=list([int(a) for a in preds['super']])\n",
    "    fine_preds_all+=list([int(a) for a in preds['sub']])\n",
    "    filenames_all+=list(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "prediction_df = pd.DataFrame({\n",
    "    'filename':filenames_all,\n",
    "    'fine_labels':fine_labels_all,\n",
    "    'coarse_labels':coarse_labels_all,\n",
    "    'fine_preds':fine_preds_all,\n",
    "    'coarse_preds':coarse_preds_all,\n",
    "    'fine_labels_string': [ind_to_class['sub'][a] for a in fine_labels_all],\n",
    "    'coarse_labels_string': [ind_to_class['super'][a] for a in coarse_labels_all]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df\n",
    "prediction_df.to_csv('predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aquatic_mammals coarse accuracy: 0.736\n",
      "seal coarse accuracy: 0.65\n",
      "beaver coarse accuracy: 0.68\n",
      "whale coarse accuracy: 0.84\n",
      "dolphin coarse accuracy: 0.82\n",
      "otter coarse accuracy: 0.69\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "coarse_class = 'aquatic_mammals'\n",
    "coarse_class_df = prediction_df[prediction_df['coarse_labels_string']==coarse_class]\n",
    "coarse_class_acc = accuracy_score(coarse_class_df['coarse_labels'],coarse_class_df['coarse_preds'])\n",
    "print(f'{coarse_class} coarse accuracy: {coarse_class_acc}')\n",
    "for fine_class in coarse_class_df['fine_labels_string'].unique():\n",
    "    fine_class_df = coarse_class_df[coarse_class_df['fine_labels_string']==fine_class]\n",
    "    fine_class_acc = accuracy_score(fine_class_df['coarse_labels'],fine_class_df['coarse_preds'])\n",
    "    print(f'{fine_class} coarse accuracy: {fine_class_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SANDBOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['large_omnivores_and_herbivores', 'reptiles', 'fruit_and_vegetables', 'people', 'fish']\n",
      "['cattle', 'dinosaur', 'apple', 'boy', 'aquarium_fish']\n"
     ]
    }
   ],
   "source": [
    "print([ind_to_class['super'][a] for a in dataloaders['super']['test'].dataset.data['coarse_labels']][0:5])\n",
    "print([ind_to_class['sub'][a] for a in dataloaders['sub']['test'].dataset.data['fine_labels']][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'aquatic_mammals',\n",
       " 1: 'fish',\n",
       " 2: 'flowers',\n",
       " 3: 'food_containers',\n",
       " 4: 'fruit_and_vegetables',\n",
       " 5: 'household_electrical_devices',\n",
       " 6: 'household_furniture',\n",
       " 7: 'insects',\n",
       " 8: 'large_carnivores',\n",
       " 9: 'large_man-made_outdoor_things',\n",
       " 10: 'large_natural_outdoor_scenes',\n",
       " 11: 'large_omnivores_and_herbivores',\n",
       " 12: 'medium_mammals',\n",
       " 13: 'non-insect_invertebrates',\n",
       " 14: 'people',\n",
       " 15: 'reptiles',\n",
       " 16: 'small_mammals',\n",
       " 17: 'trees',\n",
       " 18: 'vehicles_1',\n",
       " 19: 'vehicles_2'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_to_class['super']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fine_label': 93,\n",
       " 'coarse_label': 15,\n",
       " 'filename': 'turtle_s_000005.png',\n",
       " 'target': 15,\n",
       " 'img': tensor([[[-9.3643e-01,  1.6851e-01,  1.2974e-01,  ..., -8.7827e-01,\n",
       "           -1.2660e+00, -1.3047e+00],\n",
       "          [ 4.7867e-01,  5.7560e-01,  1.1036e-01,  ..., -4.7119e-01,\n",
       "           -6.8442e-01, -4.7119e-01],\n",
       "          [ 1.0990e+00,  4.9806e-01,  3.0421e-01,  ..., -4.4721e-02,\n",
       "           -1.0288e-01,  1.6851e-01],\n",
       "          ...,\n",
       "          [ 1.6030e+00,  1.7775e+00,  1.8938e+00,  ...,  1.3510e+00,\n",
       "            1.4673e+00,  1.5642e+00],\n",
       "          [ 1.7581e+00,  1.9325e+00,  1.9713e+00,  ...,  1.6418e+00,\n",
       "            1.5255e+00,  1.5642e+00],\n",
       "          [ 1.6805e+00,  1.7387e+00,  1.7581e+00,  ...,  1.4867e+00,\n",
       "            1.4091e+00,  1.6612e+00]],\n",
       " \n",
       "         [[-1.2776e+00, -3.3357e-01, -4.1224e-01,  ..., -1.2579e+00,\n",
       "           -1.6512e+00, -1.6906e+00],\n",
       "          [ 7.6703e-04,  4.0101e-02, -4.1224e-01,  ..., -9.4324e-01,\n",
       "           -1.1399e+00, -9.2357e-01],\n",
       "          [ 5.1211e-01, -5.8233e-02, -1.9590e-01,  ..., -5.8924e-01,\n",
       "           -6.4824e-01, -3.5324e-01],\n",
       "          ...,\n",
       "          [ 1.3971e+00,  1.5741e+00,  1.6724e+00,  ...,  8.6611e-01,\n",
       "            1.0234e+00,  1.1611e+00],\n",
       "          [ 1.5544e+00,  1.7314e+00,  1.7511e+00,  ...,  1.1414e+00,\n",
       "            1.0824e+00,  1.1611e+00],\n",
       "          [ 1.4561e+00,  1.5151e+00,  1.5544e+00,  ...,  1.0038e+00,\n",
       "            9.6444e-01,  1.2594e+00]],\n",
       " \n",
       "         [[-1.7727e+00, -1.0898e+00, -1.1483e+00,  ..., -1.4995e+00,\n",
       "           -1.8312e+00, -1.8507e+00],\n",
       "          [-8.5567e-01, -9.1420e-01, -1.2849e+00,  ..., -1.3239e+00,\n",
       "           -1.5190e+00, -1.3825e+00],\n",
       "          [-3.8743e-01, -8.7518e-01, -8.9469e-01,  ..., -1.1483e+00,\n",
       "           -1.2264e+00, -1.0508e+00],\n",
       "          ...,\n",
       "          [ 6.2711e-01,  8.8074e-01,  1.0173e+00,  ..., -1.6730e-02,\n",
       "            1.3935e-01,  2.9543e-01],\n",
       "          [ 8.0270e-01,  1.0173e+00,  1.0954e+00,  ...,  2.7592e-01,\n",
       "            1.9788e-01,  2.9543e-01],\n",
       "          [ 7.4417e-01,  8.2221e-01,  8.6123e-01,  ...,  1.1984e-01,\n",
       "            8.0821e-02,  3.9299e-01]]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders['super']['test'].dataset[105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloaders['sub']['test'].dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/cifar-100-python/test','rb') as fl:\n",
    "    test_set = pickle.load(fl, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set['filenames'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
