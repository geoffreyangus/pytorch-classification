{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "import math\n",
    "import os\n",
    "import os.path as osp\n",
    "import json\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sklearn.metrics as skl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import emmental\n",
    "from emmental import Meta\n",
    "from emmental.data import EmmentalDataset\n",
    "from emmental.data import EmmentalDataLoader\n",
    "from emmental.learner import EmmentalLearner\n",
    "from emmental.model import EmmentalModel\n",
    "from emmental.scorer import Scorer\n",
    "from emmental.task import EmmentalTask\n",
    "\n",
    "from collections import defaultdict, namedtuple\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torchvision.models import densenet121\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "from torchvision.datasets.utils import check_integrity, download_and_extract_archive\n",
    "import torchvision.transforms as transforms\n",
    "from scipy.ndimage.filters import gaussian_filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-08 19:57:28,020][INFO] emmental.meta:110 - Logging was already initialized to use /tmp/2019_12_08/19_57_15/907906c3.  To configure logging manually, call emmental.init_logging before initialiting Meta.\n",
      "[2019-12-08 19:57:28,064][INFO] emmental.meta:60 - Loading Emmental default config from /lfs/1/gangus/repositories/pytorch-classification/emmental/src/emmental/emmental-default-config.yaml.\n",
      "[2019-12-08 19:57:28,066][INFO] emmental.meta:160 - Updating Emmental config from user provided config.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'meta_config': {'seed': None, 'verbose': True, 'log_path': 'logs'},\n",
       " 'data_config': {'min_data_len': 0, 'max_data_len': 0},\n",
       " 'model_config': {'model_path': None, 'device': -1, 'dataparallel': False},\n",
       " 'learner_config': {'fp16': False,\n",
       "  'n_epochs': 1,\n",
       "  'train_split': ['train'],\n",
       "  'valid_split': ['valid'],\n",
       "  'test_split': ['test'],\n",
       "  'ignore_index': None,\n",
       "  'optimizer_config': {'optimizer': 'adam',\n",
       "   'lr': 0.001,\n",
       "   'l2': 0.0,\n",
       "   'grad_clip': None,\n",
       "   'asgd_config': {'lambd': 0.0001, 'alpha': 0.75, 't0': 1000000.0},\n",
       "   'adadelta_config': {'rho': 0.9, 'eps': 1e-06},\n",
       "   'adagrad_config': {'lr_decay': 0,\n",
       "    'initial_accumulator_value': 0,\n",
       "    'eps': 1e-10},\n",
       "   'adam_config': {'betas': (0.9, 0.999), 'eps': 1e-08, 'amsgrad': False},\n",
       "   'adamw_config': {'betas': (0.9, 0.999), 'eps': 1e-08, 'amsgrad': False},\n",
       "   'adamax_config': {'betas': (0.9, 0.999), 'eps': 1e-08},\n",
       "   'lbfgs_config': {'max_iter': 20,\n",
       "    'max_eval': None,\n",
       "    'tolerance_grad': 1e-07,\n",
       "    'tolerance_change': 1e-09,\n",
       "    'history_size': 100,\n",
       "    'line_search_fn': None},\n",
       "   'rms_prop_config': {'alpha': 0.99,\n",
       "    'eps': 1e-08,\n",
       "    'momentum': 0,\n",
       "    'centered': False},\n",
       "   'r_prop_config': {'etas': (0.5, 1.2), 'step_sizes': (1e-06, 50)},\n",
       "   'sgd_config': {'momentum': 0, 'dampening': 0, 'nesterov': False},\n",
       "   'sparse_adam_config': {'betas': (0.9, 0.999), 'eps': 1e-08},\n",
       "   'bert_adam_config': {'betas': (0.9, 0.999), 'eps': 1e-08}},\n",
       "  'lr_scheduler_config': {'lr_scheduler': None,\n",
       "   'lr_scheduler_step_unit': 'batch',\n",
       "   'lr_scheduler_step_freq': 1,\n",
       "   'warmup_steps': None,\n",
       "   'warmup_unit': 'batch',\n",
       "   'warmup_percentage': None,\n",
       "   'min_lr': 0.0,\n",
       "   'exponential_config': {'gamma': 0.9},\n",
       "   'plateau_config': {'metric': 'model/train/all/loss',\n",
       "    'mode': 'min',\n",
       "    'factor': 0.1,\n",
       "    'patience': 10,\n",
       "    'threshold': 0.0001,\n",
       "    'threshold_mode': 'rel',\n",
       "    'cooldown': 0,\n",
       "    'eps': 1e-08},\n",
       "   'step_config': {'step_size': 1, 'gamma': 0.1, 'last_epoch': -1},\n",
       "   'multi_step_config': {'milestones': [1000], 'gamma': 0.1, 'last_epoch': -1},\n",
       "   'cyclic_config': {'base_lr': 0.001,\n",
       "    'max_lr': 0.1,\n",
       "    'step_size_up': 2000,\n",
       "    'step_size_down': None,\n",
       "    'mode': 'triangular',\n",
       "    'gamma': 1.0,\n",
       "    'scale_fn': None,\n",
       "    'scale_mode': 'cycle',\n",
       "    'cycle_momentum': True,\n",
       "    'base_momentum': 0.8,\n",
       "    'max_momentum': 0.9,\n",
       "    'last_epoch': -1},\n",
       "   'one_cycle_config': {'max_lr': 0.1,\n",
       "    'pct_start': 0.3,\n",
       "    'anneal_strategy': 'cos',\n",
       "    'cycle_momentum': True,\n",
       "    'base_momentum': 0.85,\n",
       "    'max_momentum': 0.95,\n",
       "    'div_factor': 25.0,\n",
       "    'final_div_factor': 10000.0,\n",
       "    'last_epoch': -1},\n",
       "   'cosine_annealing_config': {'last_epoch': -1}},\n",
       "  'task_scheduler_config': {'task_scheduler': 'round_robin',\n",
       "   'sequential_scheduler_config': {'fillup': False},\n",
       "   'round_robin_scheduler_config': {'fillup': False},\n",
       "   'mixed_scheduler_config': {'fillup': False}},\n",
       "  'global_evaluation_metric_dict': None},\n",
       " 'logging_config': {'counter_unit': 'epoch',\n",
       "  'evaluation_freq': 1,\n",
       "  'writer_config': {'writer': 'tensorboard', 'verbose': True},\n",
       "  'checkpointing': False,\n",
       "  'checkpointer_config': {'checkpoint_path': None,\n",
       "   'checkpoint_freq': 1,\n",
       "   'checkpoint_metric': {'model/train/all/loss': 'min'},\n",
       "   'checkpoint_task_metrics': None,\n",
       "   'checkpoint_runway': 0,\n",
       "   'clear_intermediate_checkpoints': True,\n",
       "   'clear_all_checkpoints': False}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emmental.init()\n",
    "Meta.update_config({\n",
    "    'model_config': {\n",
    "        'device': -1,\n",
    "        'dataparallel': False\n",
    "    }\n",
    "})\n",
    "Meta.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR100(VisionDataset):\n",
    "    \"\"\"`CIFAR100 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where directory\n",
    "            ``cifar-10-batches-py`` exists or will be saved to if download is set to True.\n",
    "        train (bool, optional): If True, creates dataset from training set, otherwise\n",
    "            creates from test set.\n",
    "        transform (callable, optional): A function/transform that takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "        superclass (int, optinoal): If 0, use fine labels; else use coarse labels\n",
    "        subsample_subclass (dict, optional): string-float key-value pairs indicating\n",
    "            subclass to subsample and fraction of that subclass to retain at train time\n",
    "    \"\"\"\n",
    "    base_folder = 'cifar-100-python'\n",
    "    url = \"https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\"\n",
    "    filename = \"cifar-100-python.tar.gz\"\n",
    "    tgz_md5 = 'eb9058c3a382ffc7106e4002c42a8d85'\n",
    "    train_list = [\n",
    "        ['train', '16019d7e3df5f24257cddd939b257f8d'],\n",
    "    ]\n",
    "\n",
    "    test_list = [\n",
    "        ['test', 'f0ef6b0ae62326f3e7ffdfab6717acfc'],\n",
    "    ]\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None,\n",
    "                 download=False, superclass=False, subsample_subclass={}, whiten_subclass={},\n",
    "                 diff_subclass={}, switch_subclass={}, verbose=False):\n",
    "\n",
    "        super().__init__(root, transform=transform, target_transform=target_transform)\n",
    "        printv = print if verbose else lambda *args, **kwargs: None\n",
    "\n",
    "        self.train = train  # training set or test set\n",
    "        self.superclass = superclass  # use superclass labels for training\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_integrity():\n",
    "            raise RuntimeError('Dataset not found or corrupted.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "        if self.train:\n",
    "            downloaded_list = self.train_list\n",
    "        else:\n",
    "            downloaded_list = self.test_list\n",
    "\n",
    "        # Setting meta\n",
    "        if self.superclass:\n",
    "            self.target_key = 'coarse_label',\n",
    "            printv('Using coarse labels...')\n",
    "        else:\n",
    "            self.target_key = 'fine_label'\n",
    "            printv('Using fine labels...')\n",
    "\n",
    "        if isinstance(self.target_key, tuple):\n",
    "            self.target_key = self.target_key[0]\n",
    "\n",
    "        self.meta = {\n",
    "            'filename': 'meta',\n",
    "            'target_key': f'{self.target_key}_names',\n",
    "            'md5': '7973b15100ade9c7d40fb424638fde48',\n",
    "        }\n",
    "\n",
    "        file_path = os.path.join(\n",
    "            self.root, self.base_folder, 'train' if train else 'test')\n",
    "        with open(file_path, 'rb') as f:\n",
    "            if sys.version_info[0] == 2:\n",
    "                self.data = pickle.load(f)\n",
    "            else:\n",
    "                self.data = pickle.load(f, encoding='latin1')\n",
    "\n",
    "        self.data['data'] = np.vstack(self.data['data']).reshape(-1, 3, 32, 32)\n",
    "        self.data['data'] = self.data['data'].transpose(\n",
    "            (0, 2, 3, 1))  # convert to HWC\n",
    "\n",
    "        self._load_meta()\n",
    "\n",
    "        # Subsampling subclasses\n",
    "        if subsample_subclass is not {}:\n",
    "            for ky, val in subsample_subclass.items():\n",
    "                printv(\n",
    "                    f'Subsampling {ky} fine class, keeping {val*100} percent...')\n",
    "                inds = [i for i, x in enumerate(\n",
    "                    self.data['fine_labels']) if x == self.fine_class_to_idx[ky]]\n",
    "                inds = random.sample(inds, int((1-val)*len(inds)))\n",
    "                for k in self.data.keys():\n",
    "                    self.data[k] = [i for j, i in enumerate(\n",
    "                        self.data[k]) if j not in inds]\n",
    "\n",
    "        # Whitening subclasses\n",
    "        if whiten_subclass is not {}:\n",
    "            unique_coarse_labels = list(set(self.data['coarse_labels']))\n",
    "            for ky, val in whiten_subclass.items():\n",
    "                printv(\n",
    "                    f'Whitening {ky} fine class, keeping {val*100} percent...')\n",
    "                inds = [i for i, x in enumerate(\n",
    "                    self.data['fine_labels']) if x == self.fine_class_to_idx[ky]]\n",
    "                inds = random.sample(inds, int((1-val)*len(inds)))\n",
    "                for ii, _ in enumerate(self.data['coarse_labels']):\n",
    "                    if ii in inds:\n",
    "                        self.data['coarse_labels'][ii] = random.choice(\n",
    "                            unique_coarse_labels)\n",
    "\n",
    "        # Making difficult-to-discriminate subclasses\n",
    "        if diff_subclass is not {}:\n",
    "            for class_1, class_2 in diff_subclass.items():\n",
    "                printv(f'Replacing class {class_1} with blurred {class_2}...')\n",
    "                inds_c1 = [i for i, x in enumerate(\n",
    "                    self.data['fine_labels']) if x == self.fine_class_to_idx[class_1]]\n",
    "                inds_c2 = [i for i, x in enumerate(\n",
    "                    self.data['fine_labels']) if x == self.fine_class_to_idx[class_2]]\n",
    "                for ii, ind in enumerate(inds_c1):\n",
    "                    self.data['data'][ind] = gaussian_filter(\n",
    "                        self.data['data'][inds_c2[ii]], sigma=1.25)\n",
    "\n",
    "        if switch_subclass is not {}:\n",
    "            for class_1, class_2 in switch_subclass.items():\n",
    "                printv(f'Swapping {class_1} with {class_2}...')\n",
    "                inds_c1 = [i for i, x in enumerate(\n",
    "                    self.data['fine_labels']) if x == self.fine_class_to_idx[class_1]]\n",
    "                inds_c2 = [i for i, x in enumerate(\n",
    "                    self.data['fine_labels']) if x == self.fine_class_to_idx[class_2]]\n",
    "                coarse_c1 = self.data['coarse_labels'][inds_c1[0]]\n",
    "                coarse_c2 = self.data['coarse_labels'][inds_c2[0]]\n",
    "                for ind in inds_c1:\n",
    "                    self.data['coarse_labels'][ind] = coarse_c2\n",
    "                for ind in inds_c2:\n",
    "                    self.data['coarse_labels'][ind] = coarse_c1\n",
    "\n",
    "        fine_labels, coarse_labels = torch.tensor(\n",
    "            self.data['fine_labels']), torch.tensor(self.data['coarse_labels'])\n",
    "        self.num_subclasses = torch.max(fine_labels).item() + 1\n",
    "        self.num_supclasses = torch.max(coarse_labels).item() + 1\n",
    "        subclass_map = (fine_labels == torch.arange(\n",
    "            self.num_subclasses).unsqueeze(1).long()).float()\n",
    "        self.subclass_counts = subclass_map.sum(1)\n",
    "        supclass_map = (coarse_labels == torch.arange(\n",
    "            self.num_supclasses).unsqueeze(1).long()).float()\n",
    "        self.supclass_counts = supclass_map.sum(1)\n",
    "\n",
    "    def _load_meta(self):\n",
    "        path = os.path.join(self.root, self.base_folder, self.meta['filename'])\n",
    "        if not check_integrity(path, self.meta['md5']):\n",
    "            raise RuntimeError('Dataset metadata file not found or corrupted.' +\n",
    "                               ' You can use download=True to download it')\n",
    "        with open(path, 'rb') as infile:\n",
    "            if sys.version_info[0] == 2:\n",
    "                data = pickle.load(infile)\n",
    "            else:\n",
    "                data = pickle.load(infile, encoding='latin1')\n",
    "            self.classes = data[self.meta['target_key']]\n",
    "        self.class_to_idx = {_class: i for i,\n",
    "                             _class in enumerate(self.classes)}\n",
    "        self.fine_class_to_idx = {_class: i for i,\n",
    "                                  _class in enumerate(data['fine_label_names'])}\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        item_data = {\n",
    "            'fine_label': self.data['fine_labels'][index],\n",
    "            'coarse_label': self.data['coarse_labels'][index],\n",
    "            'filename': self.data['filenames'][index],\n",
    "        }\n",
    "\n",
    "        img, target = self.data['data'][index], item_data[self.target_key]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        item_data['target'] = target\n",
    "        item_data['img'] = img\n",
    "\n",
    "        return item_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data['data'])\n",
    "\n",
    "    def _check_integrity(self):\n",
    "        root = self.root\n",
    "        for fentry in (self.train_list + self.test_list):\n",
    "            filename, md5 = fentry[0], fentry[1]\n",
    "            fpath = os.path.join(root, self.base_folder, filename)\n",
    "            if not check_integrity(fpath, md5):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def download(self):\n",
    "        if self._check_integrity():\n",
    "            print('Files already downloaded and verified')\n",
    "            return\n",
    "        download_and_extract_archive(\n",
    "            self.url, self.root, filename=self.filename, md5=self.tgz_md5)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return \"Split: {}\".format(\"Train\" if self.train is True else \"Test\")\n",
    "\n",
    "\n",
    "class EmmentalCIFAR100(EmmentalDataset):\n",
    "\n",
    "    def __init__(self, root, train, transform, target_transform, download,\n",
    "                 superclass=False, subsample_subclass={}, whiten_subclass={},\n",
    "                 diff_subclass={}, switch_subclass={}, verbose=False):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.dataset = CIFAR100(\n",
    "            root, train, transform=None, target_transform=None, download=download,\n",
    "            superclass=superclass, subsample_subclass=subsample_subclass, whiten_subclass=whiten_subclass,\n",
    "            diff_subclass=diff_subclass, switch_subclass=switch_subclass, verbose=verbose)\n",
    "\n",
    "        # transforms\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        # superclass analysis\n",
    "        self.classes = self.dataset.classes\n",
    "        self.num_subclasses = self.dataset.num_subclasses\n",
    "        self.num_supclasses = self.dataset.num_supclasses\n",
    "        self.subclass_counts = self.dataset.subclass_counts\n",
    "        self.supclass_counts = self.dataset.supclass_counts\n",
    "\n",
    "        # metadata\n",
    "        self.class_to_idx = self.dataset.class_to_idx\n",
    "        self.fine_class_to_idx = self.dataset.fine_class_to_idx\n",
    "\n",
    "        # emmental init\n",
    "        X_dict = {'image_a': [], 'filename_a': []}\n",
    "        Y_dict = {'subclass_a': [], 'superclass': []}\n",
    "\n",
    "        self.superclass_to_idxs = defaultdict(list)\n",
    "        for idx, item in enumerate(self.dataset):\n",
    "            X_dict['image_a'].append(item['img'])\n",
    "            X_dict['filename_a'].append(item['filename'])\n",
    "\n",
    "            Y_dict['subclass_a'].append(item['fine_label'])\n",
    "            Y_dict['superclass'].append(item['coarse_label'])\n",
    "            \n",
    "            self.superclass_to_idxs[int(item['coarse_label'])].append(idx)\n",
    "\n",
    "        for k, v in Y_dict.items():\n",
    "            Y_dict[k] = torch.from_numpy(np.array(v))\n",
    "\n",
    "        del self.dataset\n",
    "        EmmentalDataset.__init__(\n",
    "            self, 'CIFAR100', X_dict=X_dict, Y_dict=Y_dict, uid='filename_a')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        x_dict = {k: v[idx] for k, v in self.X_dict.items()}\n",
    "        y_dict = {k: v[idx] for k, v in self.Y_dict.items()}\n",
    "\n",
    "        image_a = x_dict['image_a']\n",
    "        superclass = y_dict['superclass']\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        image_a = Image.fromarray(image_a)\n",
    "        if self.transform is not None:\n",
    "            image_a = self.transform(image_a)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            superclass = self.target_transform(superclas)\n",
    "\n",
    "        x_dict['image_a'] = image_a\n",
    "        y_dict['superclass'] = superclass\n",
    "\n",
    "        return x_dict, y_dict\n",
    "\n",
    "\n",
    "class IIC_CIFAR100(EmmentalCIFAR100):\n",
    "\n",
    "    def __init__(self, root, train, transform, target_transform, download,\n",
    "                 superclass=False, subsample_subclass={}, whiten_subclass={},\n",
    "                 diff_subclass={}, switch_subclass={}, verbose=False,\n",
    "                 pair_type='augment', pair_transform=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        assert pair_type in {\n",
    "            'augment', 'subclass'}, f'pair_type {pair_type} must be in \"augment\", \"subclass\"'\n",
    "\n",
    "        super().__init__(root, train, transform, target_transform, download,\n",
    "                         superclass=superclass, subsample_subclass=subsample_subclass,\n",
    "                         whiten_subclass=whiten_subclass, diff_subclass=diff_subclass,\n",
    "                         switch_subclass=switch_subclass, verbose=verbose)\n",
    "        self.pair_type = pair_type\n",
    "        self.pair_transform = pair_transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        x_dict = {k: v[idx] for k, v in self.X_dict.items()}\n",
    "        y_dict = {k: v[idx] for k, v in self.Y_dict.items()}\n",
    "\n",
    "        if self.transform:\n",
    "            x_dict['image_a'] = self.transform(x_dict['image_a'])\n",
    "        if self.pair_type == 'augment':\n",
    "            x_dict['image_b'] = self.pair_transform(x_dict['image_a'])\n",
    "            if self.transform:\n",
    "                x_dict['image_b'] = self.transform(x_dict['image_b'])\n",
    "            x_dict['filename_b'] = x_dict['filename_a']\n",
    "            y_dict['subclass_b'] = y_dict['subclass_a']\n",
    "        elif self.pair_type == 'subclass':\n",
    "            b_idx = random.sample(self.superclass_to_idxs[y_dict['superclass']], 1)[0]\n",
    "            x_dict['image_b'] = self.X_dict['image_a'][b_idx]\n",
    "            if self.transform:\n",
    "                x_dict['image_b'] = self.transform(x_dict['image_b'])\n",
    "            x_dict['filename_b'] = self.X_dict['filename_a'][b_idx]\n",
    "            y_dict['subclass_b'] = self.Y_dict['subclass_a'][b_idx]\n",
    "\n",
    "        return x_dict, y_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = IIC_CIFAR100(\n",
    "    root='/lfs/1/gangus/data',\n",
    "    train=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "    target_transform=None,\n",
    "    download=False,\n",
    "    superclass=True,\n",
    "    pair_type='subclass',\n",
    "    pair_transform=transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomHorizontalFlip(), \n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_class = {v: k for k, v in dataset.class_to_idx.items()}\n",
    "idx_to_fine_class = {v: k for k, v in dataset.fine_class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 60\n",
    "x, y = dataset[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 small_mammals\n",
      "36 hamster\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAJPElEQVR4nAXBSW9d53kA4Pf9xjPcc+7E4ZIiKcq2HEuNHCdO7QRtUaCrAtm02+77q7rpqosW2aQNEKSbFgoMWUrqxo4lD6pFSiYpkXc68zd/fR78yx+9A9S/fTxeLOabwRhj0jTdbDYEjIs24WLC0ySKtvcRI+XUeXMyG71Z1d/cDJ0jRmsfgouUYpwk8NZOdpfJQtDO1BORvG4VW6S0DnFw9vz1m6a3ZTnuh1pruzMuGCPBefC0HJWqXW+aPhFU+H6/lIe7Y1V3q1T2RdJsqs5GH2GwYdObjSAEgvEuYsySnJ2WyY0LTrmqbVCkramMMXmWDbWmjGZpmvFUklRSwXy/A+7HR5N3dyWVcvvGvbD2ygRFgBF0EbUP32/6JEGAhCAUEQMlbFFmfqsisHzENz40dTXKMom8r7re2sPFgY3BEGONPZxOf3578qOp2pkza83f//ndL5buk++u+kr3mAJS8N5iujaENmpWivXgGtMzJMiDLxJpBkWUOS3FKBPbrgcfAZKuc7q+SPfK3RRJ3+dY5HslzohY37RrBxH/7sHs3ZL98oVZmcABGbByJCHUYAIRxeA7NpHJmvXa6wmE2+N8t5SpYBtGyF76/Kba2pYTe29Rnk5LtW6OdmmeRbH122H86/OXj59d/MMHJ7/48E6yW//2ydNXapRxsZeEqUxLBCkRaMrGkVCKfXRH41QGwwibjMsigUmWJ0Ff9TqX8mdv7y9GxMxRgI7tUuttX8mPsuzk9OAg50VBf/FgcTyi//xkud7qo7J4d7+EoV1Vde8022EykWzdV8FhA1Apv3mzyqkPzlNGZyP+1n4yJt122xJtVdOGvs1P+eyD9z86M/7iT7DHwmSPQ/bj+7u1WP7no2cZI9wYCC5LhCaMjadjs73uQ+w9lFlRm/j8antnNxU8tlrPZ9liMROzCRcL6LW5WvXtZV2J3b/+iP9ZPjwcBKXk5H2KZf3tl/vZdn+SOOOjCwmXGU+0pOws6u/WXRvI9xTfQpeN5LpKxx5EVx3v7/70459M33lHzPeRJQCU6EG9eVEvz5xtk1u38o//NtrIjt+jChJDV1fNoO1iUoRoWq0HxtZ9z55eXDRKi4TVLn7bxuMpLVy7j+LeYv7gb/5ifO8+K48Qi8A4MBbR8tnuTvMDlIkxgs3uRO/V4OJg//Dsm9999pRTSHkkgfSWNiZ659nz62vgciS5sv6s7n29/fme/PD2/t37p8nxzjCfG1IwLSACRkc40TEnXApk2g6UcYaQIH727Vf/+uvfrFfVD2+NhqGVQgbKbAi5SFgVgWcjo5sRxEDZyWz8wcItpgRKtFEJD4FGTAyJLaoWNaGR9XXHMsnBeSOIGH/y8OG//Puvzpeb6OnrSi0OciZERv3gbZIWrJiW2Oj9NJ3Np69vVg/2knnSU4qBBVAVq65wijwV+vzZ1VfPsmySlQschoEYwlk6PWi220efPl5tqgDUeWxM7AOvlaE0Dk57T5hz+v5kcjqZPr6+0ba+W1AfWNOYXCnhNn77x+AuwZL28e/bs+9XKjJRkBgJ2tHBfnp8+r0W112DSIm1JNLW+PVgre2VUyRNd1PCNjqc6z6ieF21x+O0yFJmXNX3z5+ez+txKk2S8KHS7qI9yCSk3pu11lQ5kgCt1/2jz/+krRNSQu9CiF3wl217S9JgYV5mklPmqRi4aATj5YhhJxgRQAfj1xfD9nJ75zDlGfNqSNOMjXds8EQ1vkffOYvCBvHy4mZlQSRFJIMDTyhfK5syyKjolJccGATneCQ5K+goM04wQp1nGI+mMgIyCNpFliZ0ltHb91hxotpeVJuJVtrHQeN8/6Bu+4vXy94YFyg1RMe4HEzJmNXGM8F+cGex3ayultck0IOZEDRGDiLBTAR5MBOnRypOjMGQIj35IZu/y0kGQ0Vs8+LZl58/fFQZO97ZVZ5oe+1cFBF5ZNa6dQg1OB0CQ2ST8ez6soK6KWcFpaBpTEeSCzQQUGTZOz9Lk4PgFfIcsjHIEsoSghoHuvyv35/fbKc8c94H5yiQRHIaXTDRC1YZhz6S8wv93YutlOXBweFoOtUh6AgGQVMnrXFffq2//R8SViQtPBt5lhEqgnNvzs9mOzs/+emHWSLN0OphsM5rH1pjbPRACaM0ItY+sOpmHZ19++T2TiHTcRx8l46KSBCxY4RIIO2rZw4tzt/ji/uQTsAbtA2215fLM3Nzfvdwdq1sXQEQEoCrGDD6ESHgffDBU04OszBJWT9sAw3LqkIugQueZAITA2KgQN1AXn6B3z1k1Tl1XXQ6Ap/cevvhp//7uydfrDsD3mIMIUYPxADo4Iz3hFKMGD0hhyO+GEs/dDfLlWKZwjw433fKe4wu6F6RGKm3WF2or//bnz2BbuONc15+9bL6v+u683FVdW2vgBDnVPQOPHAmkFAHEAmyBJFlYtUP69c3LyE8KCYHZaK8dtoyH0UAq32QRBAkmzN7xhHJpiNGk2me103NUkZQBuAEA6JjyARlELFXOgB4iCwRFBPOBC43taqb1YZcxpCOKHHRWUcZIQ4JQSBAg3Wb85CJtik+f3o1yxOZZMtapzRY663zCBSBMsq8c85FZyMhgU3LgiQsEJ7zkBPqADatY1IklFlveJYkjICz/WqLzvAJYPnaanz+zTc7+4ccfaWjsxaQIDDnHBM0RgyAMYL3YE1giaAePAW/NxHzMmMmLJcVCWRnmivn7aC1D67pnLPBupTTqZgAmV5vKkpIycK6VQCZscG6gJFCJNYGQsB7QCAxAsvLpB46nsp8JJF6EJz2ebAkelOUsq6VbpxVoTVKCi6Lo/Tor+yr7aYZOKMnO5Ouv7pUVhERGBM+Bqs0xUCJCx4p8wQJUCszKlLuITbGtmB9TvhYOsY2neZJbl2oG6Wi4LOdyVvvNbT85NM/GgvrWlW1Op7NTnMooSGuimiQAhBwAEgIYqAkMsYdRsCoEClPaQBvpa/BdIq2vRVYUaOB0rycO5ZgntTDjW7X+7PJMPRdp2Z58vFRKabFF5frz84rj3n0AdATykiMFCx+/W//aI3drjbGDdk0SUal6/yb5xftdW1suHf/vu8H3/ZZLkNCF+/dlTuzYJJXLy4fPX5ydb2kAEdj/uH7pzje/af/+MPnr9oINIRACEGCNJr/B/A7y/9we9jsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F6E41C7D0F0>"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coarse_label = int(y['superclass'])\n",
    "print(coarse_label, idx_to_class[coarse_label])\n",
    "fine_label = int(y['subclass_a'])\n",
    "print(fine_label, idx_to_fine_class[fine_label])\n",
    "Image.fromarray(np.array(x['image_a'].permute(1, 2, 0) * 255, dtype=np.uint8), 'RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 small_mammals\n",
      "74 shrew\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F6E41C7D1D0>"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coarse_label = int(y['superclass'])\n",
    "print(coarse_label, idx_to_class[coarse_label])\n",
    "fine_label = int(y['subclass_b'])\n",
    "print(fine_label, idx_to_fine_class[fine_label])\n",
    "Image.fromarray(np.array(x['image_b'].permute(1, 2, 0) * 255, dtype=np.uint8), 'RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_names = ['superclass', 'iid']\n",
    "task_to_label_dict = {k: 'superclass' for k in task_names}\n",
    "split = 'train'\n",
    "dataloader = EmmentalDataLoader(\n",
    "    task_to_label_dict=task_to_label_dict,\n",
    "    dataset=dataset,\n",
    "    split=split,\n",
    "    shuffle=True if split == 'train' else False,\n",
    "    batch_size=4,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ce_loss(task_name, immediate_output_dict, Y, active):\n",
    "    module_name = f\"{task_name}_pred_head\"\n",
    "    return F.cross_entropy(\n",
    "        immediate_output_dict[module_name][0][active], Y.view(-1)[active]\n",
    "    )\n",
    "    \n",
    "\n",
    "def output(task_name, immediate_output_dict):\n",
    "    module_name = f\"{task_name}_pred_head\"\n",
    "    return immediate_output_dict[module_name][0]\n",
    "\n",
    "\n",
    "def pair_loss_iid(task_name, immediate_output_dict, Y, active, \n",
    "             lamb=1.0, EPS=sys.float_info.epsilon):\n",
    "    module_name = f\"{task_name}_pred_head\"\n",
    "    x_out, x_tf_out = [F.softmax(x, dim=-1) for x in immediate_output_dict[module_name]]\n",
    "    \n",
    "    # has had softmax applied\n",
    "    _, k = x_out.size()\n",
    "    p_i_j = compute_joint(x_out, x_tf_out)\n",
    "    assert (p_i_j.size() == (k, k))\n",
    "\n",
    "    p_i = p_i_j.sum(dim=1).view(k, 1).expand(k, k)\n",
    "    p_j = p_i_j.sum(dim=0).view(1, k).expand(k, k)  # but should be same, symmetric\n",
    "\n",
    "    # avoid NaN losses. Effect will get cancelled out by p_i_j tiny anyway\n",
    "    p_i_j[(p_i_j < EPS).data] = EPS\n",
    "    p_j[(p_j < EPS).data] = EPS\n",
    "    p_i[(p_i < EPS).data] = EPS\n",
    "\n",
    "    loss = - p_i_j * (torch.log(p_i_j) \\\n",
    "                      - lamb * torch.log(p_j) \\\n",
    "                      - lamb * torch.log(p_i))\n",
    "\n",
    "    loss = loss.sum()\n",
    "\n",
    "    loss_no_lamb = - p_i_j * (torch.log(p_i_j) \\\n",
    "                              - torch.log(p_j) \\\n",
    "                              - torch.log(p_i))\n",
    "\n",
    "    loss_no_lamb = loss_no_lamb.sum()\n",
    "\n",
    "    return loss# , loss_no_lamb\n",
    "\n",
    "\n",
    "def pair_output(task_name, immediate_output_dict):\n",
    "    module_name = f\"{task_name}_pred_head\"\n",
    "    return torch.stack(immediate_output_dict[module_name], dim=2)\n",
    "\n",
    "def compute_joint(x_out, x_tf_out):\n",
    "    # produces variable that requires grad (since args require grad)\n",
    "\n",
    "    bn, k = x_out.size()\n",
    "    assert (x_tf_out.size(0) == bn and x_tf_out.size(1) == k)\n",
    "\n",
    "    p_i_j = x_out.unsqueeze(2) * x_tf_out.unsqueeze(1)  # bn, k, k\n",
    "    p_i_j = p_i_j.sum(dim=0)  # k, k\n",
    "    p_i_j = (p_i_j + p_i_j.t()) / 2.  # symmetrise\n",
    "    p_i_j = p_i_j / p_i_j.sum()  # normalise\n",
    "\n",
    "    return p_i_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClippedDenseNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes=14, pretrained=True, weights_path=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.densenet121 = densenet121(pretrained=pretrained)\n",
    "        self.densenet121.classifier = nn.Sequential(\n",
    "            nn.Linear(self.densenet121.classifier.in_features, n_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # TODO: get this to work\n",
    "        if weights_path:\n",
    "            state_dict = torch.load(weights_path)['state_dict']\n",
    "            state_dict = {k.replace('module.densenet121', 'densenet121'): v for k, v in state_dict.items()}\n",
    "            state_dict = {k.replace('.norm.1', '.norm1'): v for k, v  in state_dict.items()}\n",
    "            state_dict = {k.replace('.norm.2', '.norm2'): v for k, v  in state_dict.items()}\n",
    "            state_dict = {k.replace('.conv.1', '.conv1'): v for k, v  in state_dict.items()}\n",
    "            state_dict = {k.replace('.conv.2', '.conv2'): v for k, v  in state_dict.items()}\n",
    "            self.load_state_dict(state_dict, strict=False)\n",
    "            num_loaded = len(set(self.state_dict().keys()) & set(state_dict.keys()))\n",
    "            num_total = len(state_dict.keys())\n",
    "            if num_loaded < num_total:\n",
    "                missing_params = set(state_dict.keys()).symmetric_difference(set(self.state_dict().keys()))\n",
    "                logging.info(\"Could not load these parameters due to name mismatch: \" + str(missing_params))\n",
    "            logging.info(f\"Loaded {num_loaded}/{num_total} pretrained parameters\")\n",
    "            \n",
    "        self.densenet121.classifier = nn.Identity()\n",
    "        \n",
    "    def forward(self, x1, x2=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        if x2 is None:\n",
    "            return self.densenet121(x1)\n",
    "        else:\n",
    "            return self.densenet121(x1), self.densenet121(x2)\n",
    "        \n",
    "class ClusterModule(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_features=1024, out_features=100):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Linear(in_features, out_features)\n",
    "        \n",
    "    def forward(self, x1, x2=None):\n",
    "        if x2 is None:\n",
    "            return self.classifier(x1)\n",
    "        else:\n",
    "            return self.classifier(x1), self.classifier(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-08 19:59:35,460][INFO] emmental.task:48 - Created task: superclass\n",
      "[2019-12-08 19:59:35,462][INFO] emmental.task:48 - Created task: iid\n"
     ]
    }
   ],
   "source": [
    "encoder_module = ClippedDenseNet(n_classes=14, pretrained=False, weights_path=None)\n",
    "decoder_module = nn.Linear(1024, 20)\n",
    "cluster_module = ClusterModule(1024, 100)\n",
    "\n",
    "tasks = [      \n",
    "    EmmentalTask(\n",
    "        name='superclass',\n",
    "        module_pool=nn.ModuleDict({\n",
    "            'encoder': encoder_module,\n",
    "            'decoder': decoder_module\n",
    "        }),\n",
    "        task_flow=[\n",
    "            {\n",
    "                'name': 'encoder',\n",
    "                'module': 'encoder',\n",
    "                'inputs': [('_input_', 'image_a'), ('_input_', 'image_b')]\n",
    "            },\n",
    "            {\n",
    "                'name': 'superclass_pred_head',\n",
    "                'module': 'decoder',\n",
    "                'inputs': [('encoder', 0)]\n",
    "            }\n",
    "        ],\n",
    "        loss_func=partial(ce_loss, 'superclass'),\n",
    "        output_func=partial(output, 'superclass'),\n",
    "        scorer=Scorer(metrics=[\"accuracy\"]),\n",
    "    ),\n",
    "    EmmentalTask(\n",
    "        name='iid',\n",
    "        module_pool=nn.ModuleDict({\n",
    "            'encoder': encoder_module,\n",
    "            'cluster': cluster_module\n",
    "        }),\n",
    "        task_flow=[\n",
    "            {\n",
    "                'name': 'encoder',\n",
    "                'module': 'encoder',\n",
    "                'inputs': [('_input_', 'image_a'), ('_input_', 'image_b')]\n",
    "            },\n",
    "            {\n",
    "                'name': 'iid_pred_head',\n",
    "                'module': 'cluster',\n",
    "                'inputs': [('encoder', 0), ('encoder', 1)]\n",
    "            }\n",
    "        ],\n",
    "        loss_func=partial(pair_loss_iid, 'iid'),\n",
    "        output_func=partial(pair_output, 'iid'),\n",
    "        scorer=Scorer(metrics=[]),\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-12-08 19:59:35,592][INFO] emmental.model:57 - Created emmental model IIC that contains task {'superclass', 'iid'}.\n"
     ]
    }
   ],
   "source": [
    "model = EmmentalModel(name='IIC', tasks=tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
