{
  "artifacts": [],
  "command": "main",
  "experiment": {
    "base_dir": "/lfs/1/gangus/repositories/pytorch-classification/drain_detector",
    "dependencies": [
      "emmental==0.0.5",
      "numpy==1.17.4",
      "sacred==0.8.0",
      "torch==1.3.1",
      "torchvision==0.4.2"
    ],
    "mainfile": "train_drain.py",
    "name": "trainer",
    "repositories": [
      {
        "commit": "f2c4c037d60f832b9d893e77e457d4c17591110d",
        "dirty": true,
        "url": "https://github.com/geoffreyangus/pytorch-classification.git"
      },
      {
        "commit": "f2c4c037d60f832b9d893e77e457d4c17591110d",
        "dirty": true,
        "url": "https://github.com/geoffreyangus/pytorch-classification.git"
      },
      {
        "commit": "f2c4c037d60f832b9d893e77e457d4c17591110d",
        "dirty": true,
        "url": "https://github.com/geoffreyangus/pytorch-classification.git"
      },
      {
        "commit": "f2c4c037d60f832b9d893e77e457d4c17591110d",
        "dirty": true,
        "url": "https://github.com/geoffreyangus/pytorch-classification.git"
      },
      {
        "commit": "f2c4c037d60f832b9d893e77e457d4c17591110d",
        "dirty": true,
        "url": "https://github.com/geoffreyangus/pytorch-classification.git"
      }
    ],
    "sources": [
      [
        "dataset.py",
        "_sources/dataset_e72d91fabd7ab440e409365d55d34b41.py"
      ],
      [
        "modules.py",
        "_sources/modules_94caa083981a19b71921235869a3ee43.py"
      ],
      [
        "train_drain.py",
        "_sources/train_drain_61d2849b27ae7d9a69b2b3a7fa7c5456.py"
      ],
      [
        "transforms.py",
        "_sources/transforms_275b0b3be4ec4d07f91efa0c6a88e6ba.py"
      ],
      [
        "util.py",
        "_sources/util_2774e082f3012ada65d055e1f8fe5608.py"
      ]
    ]
  },
  "fail_trace": [
    "Traceback (most recent call last):\n",
    "  File \"/lfs/1/gangus/repositories/pytorch-classification/.env-pytorch-classification/lib/python3.6/site-packages/sacred/config/captured_function.py\", line 42, in captured_function\n    result = wrapped(*args, **kwargs)\n",
    "  File \"train_drain.py\", line 286, in main\n    trainer = TrainingHarness()\n",
    "  File \"train_drain.py\", line 175, in __init__\n    self.model = self._init_model()\n",
    "  File \"/lfs/1/gangus/repositories/pytorch-classification/.env-pytorch-classification/lib/python3.6/site-packages/sacred/config/captured_function.py\", line 42, in captured_function\n    result = wrapped(*args, **kwargs)\n",
    "  File \"train_drain.py\", line 242, in _init_model\n    encoder_module = getattr(modules, encoder_class)(**encoder_args)\n",
    "  File \"/lfs/1/gangus/repositories/pytorch-classification/drain_detector/modules.py\", line 42, in __init__\n    self.densenet121 = densenet121(pretrained=pretrained)\n",
    "  File \"/lfs/1/gangus/repositories/pytorch-classification/.env-pytorch-classification/lib/python3.6/site-packages/torchvision/models/densenet.py\", line 200, in densenet121\n    **kwargs)\n",
    "  File \"/lfs/1/gangus/repositories/pytorch-classification/.env-pytorch-classification/lib/python3.6/site-packages/torchvision/models/densenet.py\", line 185, in _densenet\n    _load_state_dict(model, model_urls[arch], progress)\n",
    "  File \"/lfs/1/gangus/repositories/pytorch-classification/.env-pytorch-classification/lib/python3.6/site-packages/torchvision/models/densenet.py\", line 171, in _load_state_dict\n    state_dict = load_state_dict_from_url(model_url, progress=progress)\n",
    "  File \"/lfs/1/gangus/repositories/pytorch-classification/.env-pytorch-classification/lib/python3.6/site-packages/torch/hub.py\", line 470, in load_state_dict_from_url\n    os.makedirs(model_dir)\n",
    "  File \"/usr/local/lib/python3.6/os.py\", line 210, in makedirs\n    makedirs(head, mode, exist_ok)\n",
    "  File \"/usr/local/lib/python3.6/os.py\", line 210, in makedirs\n    makedirs(head, mode, exist_ok)\n",
    "  File \"/usr/local/lib/python3.6/os.py\", line 210, in makedirs\n    makedirs(head, mode, exist_ok)\n",
    "  File \"/usr/local/lib/python3.6/os.py\", line 220, in makedirs\n    mkdir(name, mode)\n",
    "PermissionError: [Errno 13] Permission denied: '/afs/cs.stanford.edu/u/gangus'\n"
  ],
  "heartbeat": "2019-11-18T03:55:56.165469",
  "host": {
    "ENV": {},
    "cpu": "Intel(R) Xeon(R) CPU E5-2690 v4 @ 2.60GHz",
    "gpus": {
      "driver_version": "430.26",
      "gpus": [
        {
          "model": "Tesla P100-PCIE-16GB",
          "persistence_mode": true,
          "total_memory": 16280
        }
      ]
    },
    "hostname": "dawn5.stanford.edu",
    "os": [
      "Linux",
      "Linux-4.4.0-124-generic-x86_64-with-debian-stretch-sid"
    ],
    "python_version": "3.6.7"
  },
  "meta": {
    "command": "main",
    "comment": "this experiment runs a model for drain detection on chexnet/segmentation joint images with a densenet pretrained on imagenet",
    "options": {
      "--beat-interval": null,
      "--capture": null,
      "--comment": "this experiment runs a model for drain detection on chexnet/segmentation joint images with a densenet pretrained on imagenet",
      "--debug": false,
      "--enforce_clean": false,
      "--file_storage": null,
      "--force": false,
      "--help": false,
      "--loglevel": null,
      "--mongo_db": null,
      "--name": null,
      "--pdb": false,
      "--print-config": true,
      "--priority": null,
      "--queue": false,
      "--s3": null,
      "--sql": null,
      "--tiny_db": null,
      "--unobserve": false,
      "COMMAND": null,
      "UPDATE": [
        "cxr_only=False",
        "pretrain_imagenet=True"
      ],
      "help": false,
      "with": true
    }
  },
  "resources": [],
  "result": null,
  "start_time": "2019-11-18T03:55:55.906921",
  "status": "FAILED",
  "stop_time": "2019-11-18T03:55:56.168247"
}